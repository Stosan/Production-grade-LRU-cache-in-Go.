# HyperLRU ğŸš€

A **high-throughput, concurrent-safe LRU (Least Recently Used) cache** for Go â€” engineered to handle **millions of keys** with minimal lock contention.  

Built for **high-impact systems** where performance, scalability, and reliability are non-negotiable.  

---

## âš¡ Why HyperLRU?
- **Concurrency-first** â†’ optimized for multi-goroutine workloads.  
- **Scales to millions** â†’ configurable max capacity for large datasets.  
- **Minimal lock contention** â†’ efficient synchronization for speed.  
- **True LRU eviction** â†’ least recently used items are automatically removed.  
- **Production-r**

### Try it out
```go
go run main.go

```


## ğŸ—ï¸ Use Cases

High-throughput caching in distributed systems

Real-time analytics pipelines

Web services with massive request volume

Systems where predictable eviction (LRU) is critical
